---
title: "Road accidents in New York"
author: "Luca Renz & Alvaro Cervan"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: true
    df_print: paged
    theme: cosmo
    highlight: tango
---

## Road accidents in New York
```{r setup, include=FALSE}
# Global options
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
knitr::opts_chunk$set(cache=TRUE)
```

This analysis aims to provide some insight about the car crashes in New York during the period of 2016 to 2022, focusing on some key factors such as vehicle type, hour and weather.

## Files
This analysis counts with 2 datasets, one containing the vehicle crashes and the second one about the weather of the location.

| Name     | Rows     | Columns | Each row is a    | Link                                                                                      |
|:------:|:----:|:---:|:--------:|:----:|
| **Vehicles dataset**       | 2.11M    | 29      | Motor Vehicle Collision                | [Vehicles dataset](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95/data_preview) |
| **Weather dataset**        | 59,760   | 10      | Time stamp of Weather                  | [Weather dataset](https://www.kaggle.com/datasets/aadimator/nyc-weather-2016-to-2022?resource=download)                |

## Data Preparation

In this step, it is shown how the data was collected from the datasets, cleaned, and merged to create a comprehensive dataset for analysis. Before merging, the data was cleaned and enriched with additional information. Additionally, the data was shrunk to make it more manageable.

### Data Cleaning

The data cleaning process involves removing columns with high NA ratios, filtering out rows with missing values, and creating new columns to categorize the main causes of accidents. The data is then enriched with additional information such as the day of the week, month, quarter, year, and time of day.

Both datasets, specially `vehicles.csv`, contain a lot of rows which require a lot of memory and time to process. For this reason, it has been decided to eliminate rows with missing values and columns with high NA ratios, such as vehicle type 3, 4 and 5 as there are very few values in these columns (multiple vehicle accidents).

`Weather.xlsx` is a smaller dataset and the cleaning process is simpler, that just need to be convert the time column to a correct format and rename some columns for better understanding.
Finally, the data is then merged with the weather data to create a comprehensive dataset for analysis.

```{r Data Cleaning, eval=FALSE}
  ## packages
  library(lubridate) # used to round to the next hour
  library(dplyr)
  library(readxl)
  
  # VEHICLES DF - CLEANING
  vehicles_df <- read.csv("data/vehicles.csv", header=TRUE)
  
  ## columns to be removed due to high NaN ratio.
  columns_to_remove <- c(
    "CROSS.STREET.NAME",
    "ON.STREET.NAME",
    "OFF.STREET.NAME", 
    "CONTRIBUTING.FACTOR.VEHICLE.3",
    "CONTRIBUTING.FACTOR.VEHICLE.4", 
    "CONTRIBUTING.FACTOR.VEHICLE.5",
    "VEHICLE.TYPE.CODE.3",
    "VEHICLE.TYPE.CODE.4",
    "VEHICLE.TYPE.CODE.5",
    "COLLISION_ID"
  )
  
  min_cutoff_date <- as.Date("2016-01-01")
  max_cutoff_date <- as.Date("2022-01-01")
  
  ## Create broader categories for main causes
  conditions <- c("Aggressive Driving/Road Rage", "Pavement Slippery", "Following Too Closely", 
                  "Unspecified", "", "Passing Too Closely", "Driver Inexperience", 
                  "Passing or Lane Usage Improper", "Turning Improperly", "Unsafe Lane Changing", 
                  "Unsafe Speed", "Reaction to Uninvolved Vehicle", "Steering Failure", 
                  "Traffic Control Disregarded", "Other Vehicular", "Driver Inattention/Distraction", 
                  "Oversized Vehicle", "Pedestrian/Bicyclist/Other Pedestrian Error/Confusion", 
                  "Alcohol Involvement", "View Obstructed/Limited", "Failure to Yield Right-of-Way", 
                  "Illnes", "Lost Consciousness", "Brakes Defective", "Backing Unsafely", "Glare", 
                  "Passenger Distraction", "Fell Asleep", "Obstruction/Debris", "Tinted Windows", 
                  "Animals Action", "Drugs (illegal)", "Pavement Defective", "Other Lighting Defects", 
                  "Outside Car Distraction", "Driverless/Runaway Vehicle", "Tire Failure/Inadequate", 
                  "Fatigued/Drowsy", "Headlights Defective", "Accelerator Defective", 
                  "Failure to Keep Right", "Physical Disability", "Eating or Drinking", 
                  "Cell Phone (hands-free)", "Lane Marking Improper/Inadequate", 
                  "Cell Phone (hand-Held)", "Using On Board Navigation Device", "Other Electronic Device", 
                  "Traffic Control Device Improper/Non-Working", "Tow Hitch Defective", 
                  "Windshield Inadequate", "Vehicle Vandalism", "Shoulders Defective/Improper", 
                  "Prescription Medication", "Listening/Using Headphones", "Texting", "80", 
                  "Reaction to Other Uninvolved Vehicle", "1", "Drugs (Illegal)", "Illness", 
                  "Cell Phone (hand-held)")
  
  ## mapping for conditions
  categorize_condition <- function(condition) {
    if (grepl("Driving|Following|Passing|Inexperience|Improper|Changing|Speed|Distraction|Alcohol|Drugs|Phone|Eating|Fatigued|Sleeping|Pedestrian|Failure to Yield|Backing|Oversized", condition, ignore.case = TRUE)) {
      return("Human Error")
    } else if (grepl("Brakes|Steering|Tire|Headlights|Accelerator|Windshield|Tow Hitch|Defective|Failure", condition, ignore.case = TRUE)) {
      return("Mechanical Error")
    } else if (grepl("Pavement|Glare|Obstruction|Weather|Animals|View|Control|Shoulders", condition, ignore.case = TRUE)) {
      return("Environmental Conditions")
    } else if (grepl("Illness|Lost Consciousness|Physical Disability", condition, ignore.case = TRUE)) {
      return("Medical Condition")
    } else if (condition == "" || grepl("Unspecified|Other", condition, ignore.case = TRUE)) {
      return("Other/Unspecified")
    } else {
      return("Other/Unspecified")
    }
  }
  
  vehicles_df <- vehicles_df %>%
    mutate(CRASH.DATE = as.Date(CRASH.DATE, format = "%m/%d/%Y")) %>%  # Convert CRASH.DATE to Date format
    select(-all_of(columns_to_remove)) %>%
    filter(CRASH.DATE >= min_cutoff_date) %>%
    filter(CRASH.DATE < max_cutoff_date) %>%
    filter(!is.na(LATITUDE) & !is.na(LONGITUDE)) %>%
    filter(LATITUDE != 0 | LONGITUDE != 0) %>%
    filter(!is.na(CRASH.TIME)) %>%
    ##create new column with broader category for accident
    mutate(Category = sapply(CONTRIBUTING.FACTOR.VEHICLE.1, categorize_condition)) %>%
    # Combine date and time into one string
    mutate(CRASH.DATETIME = as.POSIXct(paste(CRASH.DATE, CRASH.TIME), format = "%Y-%m-%d %H:%M")) %>%
    # Round down to the current hour
    mutate(CRASH.DATETIME = floor_date(CRASH.DATETIME, "hour")) %>%
    # enriching datetime format to weekdays, month, quarter, year
    mutate(
      Weekday = wday(CRASH.DATETIME, label = TRUE, abbr = FALSE), 
      Month = month(CRASH.DATETIME, label = TRUE, abbr = FALSE),  
      Quarter = quarter(CRASH.DATETIME),                          
      Year = year(CRASH.DATETIME) ,
      Day = day(CRASH.DATETIME),
      Hour = hour(CRASH.DATETIME),  
      TimeOfDay = case_when(                      
        Hour >= 6 & Hour < 12  ~ "Morning",
        Hour >= 12 & Hour < 17 ~ "Afternoon",
        Hour >= 17 & Hour < 20 ~ "Late Afternoon",
        Hour >= 20 ~ "Night",
        Hour < 6 ~ "Early Morning",
        TRUE ~ "Unknown",
      )
    ) %>%
    filter(!is.na(CRASH.TIME)) %>%
    mutate(IS.DEADLY.ACCIDENT = (NUMBER.OF.PERSONS.KILLED + NUMBER.OF.PEDESTRIANS.KILLED + NUMBER.OF.CYCLIST.KILLED + NUMBER.OF.MOTORIST.KILLED) > 0,
           IS.INJURED.ACCIDENT = (NUMBER.OF.PERSONS.INJURED + NUMBER.OF.PEDESTRIANS.INJURED + NUMBER.OF.CYCLIST.INJURED + NUMBER.OF.MOTORIST.INJURED) > 0)
  
  # WEATHER DF - CLEANING
  weather_df <- read_excel("data/weather.xlsx")
  weather_df <- weather_df %>%
    rename("temperature_celsius" = "temperature_2m (Â°C)", "winddirection_10m_degrees" = "winddirection_10m (Â°)") %>%
    mutate(time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M")) %>% # Convert the TIME column to correct format
    filter(!is.na(time)) %>% #filter rows where there is no time 
    filter(rowSums(is.na(.)) / ncol(weather_df) < 0.8) # Filter rows where 80% or more columns are NaN/Na
  
  # MERGING DATAFRAMES
  merged_df <- left_join(vehicles_df, weather_df, by = c("CRASH.DATETIME" = "time"))
  
  write.csv(merged_df,"merged_all_years.csv")
  
  split_datasets <- split(merged_df, merged_df$Year)
  
  # Save each year to a separate file
  lapply(names(split_datasets), function(year) {
    filename <- paste0("merged_data_", year, ".csv")
    write.csv(split_datasets[[year]], file = filename, row.names = FALSE)
  })


```

The result is:
```{r Merged Dataframe Size, eval=FALSE}
merged_df <- read.csv("data/merged_all_years.csv", header = TRUE)
str(merged_df)
```

| Name            | Rows     | Columns | Each row is a                          |
|:-------:|:-----:|:----:|:------:|
| **Merged dataset** | 1M | 40      | Combination of vehicle and weather data |

After merging the data, it is saved each year in a separate file to make it easier to analyze the data by year. 
This way is possible to perform both analyses on the full dataset and on years separately.

```{r Save Data by Year, eval=FALSE}
# Save each year to a separate file
lapply(names(split_datasets), function(year) {
  filename <- paste0("data/merged_data_", year, ".csv")
  write.csv(split_datasets[[year]], file = filename, row.names = FALSE)
})

```

## Analysis
The following subsections illustrate the insights gained by generating plots of the given datasets.

### Total Accidents in New York

```{r total_accidents}
# Loading necessary libraries
library(ggplot2)
library(dplyr)

# Load the data from a CSV file
data <- read.csv("data/merged_all_years.csv", header = TRUE)

# Convert the CRASH.DATE into a Date object
data$CRASH.DATE <- as.Date(data$CRASH.DATE, "%d/%m/%Y")

# Aggregating data by Year
yearly_accidents <- data %>%
  group_by(Year) %>%
  summarise(Total_Accidents = n(), .groups = 'drop')

# Plotting the data
ggplot(yearly_accidents, aes(x = Year, y = Total_Accidents, fill = Year)) +
  geom_bar(stat = "identity") +  # Set a single color for the bars
  labs(title = "Total Accidents per Year",
       x = "Year",
       y = "Number of Accidents") + theme_minimal() + theme(legend.position = "none")

```
As it is known, New York City is the city that never sleeps. Therefore, several thousands of people are on the road which can lead to some traffic jam and car crashes. Therefore, the first step was to have a very broad understanding of the rough numbers. For this reason, the first plot has been created to see, how many accidents there were in the last few years.

So in this graph the total number of accidents per year in New York from 2016 to 2022 are shown.
The number of accidents seems to be decreasing over the years, which is a positive trend.

It is important to note that no conclusions can be drawn from this graph alone, as other factors may have influenced the number of accidents, such as the COVID-19 pandemic and the lockdowns that occurred in 2020 and 2021, which could have reduced the number of vehicles on the road and, consequently, the number of accidents.

### Correlation between Total Accidents and Total Rainfall per Month
```{r Correlation}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(lubridate)
library(readxl)

# Load the data
accident_data <- read.csv("data/merged_data_2021.csv", header = TRUE)
weather_data <- read_excel("data/weather_2021.xlsx")

# Step 1: Extract Date and Hour from the 'time' column in the weather data
weather_data <- weather_data %>%
  mutate(time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M"))

# Step 2: Convert CRASH.DATE in accident_data to Date type
accident_data <- accident_data %>%
  mutate(CRASH.DATE = as.Date(CRASH.DATE, format = "%Y-%m-%d"))

# Step 3: Match accidents with corresponding hourly rainfall data
accident_data <- accident_data %>%
  mutate(CRASH.DATETIME = as.POSIXct(paste(CRASH.DATE, CRASH.TIME), format = "%Y-%m-%d %H:%M")) %>%
  mutate(CRASH.DATETIME = floor_date(CRASH.DATETIME, "hour"))

accidents_with_rainfall <- left_join(accident_data, weather_data, by = c("CRASH.DATETIME" = "time"))

# Step 4: Categorize rainfall into meaningful bins
accidents_with_rainfall <- accidents_with_rainfall %>%
  mutate(Rainfall_Category = case_when(
    rain..mm. == 0 ~ "0 mm (No rain)",
    rain..mm. > 0 & rain..mm. <= 4 ~ "1 mm - 4 mm (Light rain)",
    rain..mm. > 4 & rain..mm. <= 7 ~ ">4 mm - 7 mm (Moderate rain)",
    rain..mm. > 7 ~ ">7 mm (Heavy rain)"
  ))

# Step 5: Group data by Month and Rainfall Category
accidents_by_month_rainfall <- accidents_with_rainfall %>%
  mutate(Month = month(CRASH.DATETIME, label = TRUE)) %>%
  group_by(Month) %>%
  summarise(Total_Accidents = n(), .groups = 'drop')

# Step 6: Calculate total rainfall per month
total_rainfall_per_month <- weather_data %>%
  mutate(Month = month(time, label = TRUE)) %>%
  group_by(Month) %>%
  summarise(Total_Rainfall = sum(`rain (mm)`))

# Step 7: Merge the accident data with the rainfall data
correlation_data <- left_join(accidents_by_month_rainfall, total_rainfall_per_month, by = "Month")

# Step 8: Calculate the correlation coefficient
correlation_coefficient <- cor(correlation_data$Total_Accidents, correlation_data$Total_Rainfall)
print(paste("Correlation coefficient:", round(correlation_coefficient, 2)))

# Step 9: Plot the correlation with labels
ggplot(correlation_data, aes(x = Total_Rainfall, y = Total_Accidents)) +
  geom_point(aes(color = Month), size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_text(aes(label = Month), vjust = -1, hjust = 1, size = 4) +
  labs(title = paste("Correlation between Total Accidents and Total Rainfall per Month\nCorrelation coefficient:", round(correlation_coefficient, 2)),
       x = "Total Rainfall (mm)",
       y = "Total Accidents") +
  theme_minimal() +
  theme(legend.position = "right") +
  scale_color_discrete(name = "Month")

```

This graph shows the correlation between the total number of accidents and the total rainfall per month in New York in 2021. The result of `0.59` indicates a moderate positive correlation between the two variables, suggesting that higher rainfall may lead to more accidents. Nevertheless, there may be multiple other factors influencing the final result such as how many cars/people are on the road, any events or other environmental exposure.

### Monthly Accidents and Rainfall

```{r Monthly Accidents and Rainfall, fig.cap="Monthly Number of Accidents by Rainfall Category with Monthly Rainfall"}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(lubridate)
library(readxl)

# Load the data
accident_data <- read.csv("data/merged_data_2021.csv", header = TRUE)
weather_data <- read_excel("data/weather_2021.xlsx")

# Step 1: Extract Date and Hour from the 'time' column in the weather data
weather_data <- weather_data %>%
  mutate(time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M"))

# Step 2: Convert CRASH.DATE in accident_data to Date type
accident_data <- accident_data %>%
  mutate(CRASH.DATE = as.Date(CRASH.DATE, format = "%Y-%m-%d"))

# Step 3: Match accidents with corresponding hourly rainfall data
accident_data <- accident_data %>%
  mutate(CRASH.DATETIME = as.POSIXct(paste(CRASH.DATE, CRASH.TIME), format = "%Y-%m-%d %H:%M")) %>%
  mutate(CRASH.DATETIME = floor_date(CRASH.DATETIME, "hour"))

accidents_with_rainfall <- left_join(accident_data, weather_data, by = c("CRASH.DATETIME" = "time"))

# Step 4: Categorize rainfall into meaningful bins
accidents_with_rainfall <- accidents_with_rainfall %>%
  mutate(Rainfall_Category = case_when(
    rain..mm. == 0 ~ "0 mm (No rain)",
    rain..mm. > 0 & rain..mm. <= 4 ~ "1 mm - 4 mm (Light rain)",
    rain..mm. > 4 & rain..mm. <= 7 ~ ">4 mm - 7 mm (Moderate rain)",
    rain..mm. > 7 ~ ">7 mm (Heavy rain)"
  ))

# Step 5: Group data by Month and Rainfall Category
accidents_by_month_rainfall <- accidents_with_rainfall %>%
  mutate(Month = month(CRASH.DATETIME, label = TRUE)) %>%
  group_by(Month, Rainfall_Category) %>%
  summarise(Total_Accidents = n(), .groups = 'drop') %>%
  filter(!is.na(Rainfall_Category))  # Drop NA values

# Step 6: Calculate the total number of accidents per month across all categories
total_accidents_per_month <- accidents_by_month_rainfall %>%
  group_by(Month) %>%
  summarise(Total_Accidents_Month = sum(Total_Accidents))

# Step 7: Calculate total rainfall per month
total_rainfall_per_month <- weather_data %>%
  mutate(Month = month(time, label = TRUE)) %>%
  group_by(Month) %>%
  summarise(Total_Rainfall = sum(`rain (mm)`))

# Step 8: Plot the data with dots for each category and a line for the total accidents
ggplot() +
  # Add dots for each category with transparency
  geom_point(data = accidents_by_month_rainfall, aes(x = Month, y = Total_Accidents, color = Rainfall_Category), size = 3, alpha = 0.3) +
  # Add a line for the total number of accidents per month
  geom_line(data = total_accidents_per_month, aes(x = Month, y = Total_Accidents_Month, group = 1), color = "black", size = 1) +
  # Add a secondary bar plot for total rainfall per month with a secondary y-axis
  geom_bar(data = total_rainfall_per_month, aes(x = Month, y = Total_Rainfall * 50), stat = "identity", fill = "blue", alpha = 0.3) +
  scale_y_continuous(
    name = "Number of Accidents",
    sec.axis = sec_axis(~./50, name = "Total Rainfall (mm)")
  ) +
  labs(title = "Monthly Number of Accidents by Rainfall Category with Monthly Rainfall",
       x = "Month") +
  theme_minimal() +
  theme(legend.position = "right")
```

This graph shows the monthly number of accidents in New York in 2021, categorized by rainfall intensity.
The black line represents the total number of accidents per month, while the blue bars represent the total rainfall per month on a secondary y-axis. The dots represent the number of accidents in each rainfall category. 

It can be appreciated that the number of accidents tends to increase with higher rainfall, especially in the "1 mm - 4 mm (Light rain)" and ">4 mm - 7 mm (Moderate rain)" categories.

At the same time, the majority of accidents occur in no rain conditions, which could be due simply to the fact that most of the time there is no rain in New York. Hence, ithout the a total amount of vehicles on the road, it is difficult to draw conclusions from this data alone.

### Temporal Analysis

Here the goal is to analyze the distribution of accidents by hour, day of the week, and month.

Hopefully, this analysis provides insights into the temporal patterns of accidents in New York, helping to identify high-risk and safer periods.


```{r Processing v2, echo=FALSE, cache=TRUE}
# Load necessary libraries
library(tidyverse)
library(lubridate)
library(sf)
library(leaflet)
library(leaflet.extras)
library(scales)
library(treemapify)
library(corrplot)

accidents <- read.csv("data/merged_data_2021.csv")

# Data Preprocessing
accidents <- accidents %>%
  mutate(
    CRASH.DATETIME = ymd_hms(CRASH.DATETIME),
    Year = year(CRASH.DATETIME),
    Month = factor(month(CRASH.DATETIME), levels = 1:12, 
                   labels = month.abb, ordered = TRUE),
    Day = day(CRASH.DATETIME),
    Hour = hour(CRASH.DATETIME),
    Weekday = factor(wday(CRASH.DATETIME, week_start = 1), levels = 1:7, 
                     labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"), ordered = TRUE)
  ) %>%
  filter(LATITUDE != 0 & LONGITUDE != 0) %>%  # Remove lat/long = 0
  filter(BOROUGH != "" & !is.na(BOROUGH) & trimws(BOROUGH) != "")  # Remove empty or space-only BOROUGH entries
```

#### Accidents by Hour

```{r Temporal Analysis by hour, cache=TRUE}
# 1. Temporal Analysis
## Accidents by Hour
ggplot(accidents, aes(x = Hour, y = ..count..)) +
  geom_density(fill = "skyblue", alpha = 0.7) +
  coord_polar(start = 0) +  # Start the polar plot at 0
  labs(title = "Distribution of Accidents by Hour", x = "", y = "") +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 24, by = 1), limits = c(0, 24, NA))  # Set breaks from 0 to 24 and limit the x-axis
```

The hourly analysis shows accidents in New York throughout the 24h of each day. Accidents don't dip below the thousand at anytime, rising quickly from the early morning around 4AM to 8AM, when the rise slows down until 4PM to 5PM, which represent the peak hour for accidents. These hours represent the movement in the city, from 7AM where the inhabitants move to work, school etc. Around 5PM, where the max is, can be identified with the "Rush hour" where most of the workers end their shift and commute.

After 6PM, a slow decline in accidents continues during the evening and night until the next morning.

#### Accidents by Time of Day

```{r Time of the Day Analysis, cache=TRUE}
# time of the day (morning, night, evening) with the highest number of accidents
accidents %>%
  
  count(TimeOfDay) %>%
  ggplot(aes(x = TimeOfDay, y = n, fill = TimeOfDay)) +
  geom_col() +
  labs(title = "Number of Accidents by Time of Day", x = "Time of Day", y = "Number of Accidents") +
  theme_minimal()
```

This plot is higly related to the previous one, as it shows the same information but in a different way, by grouping the hours in 4 categories, which are Morning, Afternoon, Late Afternoon and Night.

The graph illustrates that the likelihood of accidents in New York varies significantly depending on the time of day. The highest number of accidents occurs in the afternoon, followed by the evening. This trend suggests that increased traffic during these times, possibly due to people commuting home from work or school, contributes to a higher accident rate.

In contrast, the morning sees fewer accidents, which might be attributed to lighter traffic or more cautious driving as people start their day. The night has the lowest number of accidents, likely due to reduced traffic volume and fewer vehicles on the road.

Overall, the graph highlights the importance of being particularly cautious during the afternoon and evening when the risk of accidents is highest.

#### Accidents by Day of Week

```{r Temporal Analysis by Day}
## Accidents by Day of Week
# filter NA values
accidents <- accidents %>% filter(!is.na(Weekday))
ggplot(accidents, aes(x = Weekday, y = ..count.., group = 1)) +
  geom_line(stat = "count", color = "lightgreen", size = 1.5) +
  geom_point(stat = "count", color = "darkgreen", size = 3) +
  labs(title = "Distribution of Accidents by Day of Week", x = "", y = "Number of Accidents") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

On a daily basis, it's appreciated how differences between days can be huge. 

From the start of the week, until Wednesday there is a stable number of accidents, around the 9500. Here it starts to grow slightly until Thursday. On the last working day, on Friday, they rise steeply about a 10%, which could be linked to many factors, including that is the day that most people decide to go out or they move to outside New York for the weekend for different reasons (eg. visiting family, vacation...)

On the weekend on the other hand, maybe a bit counterintuitive, there is a substantial drop in accidents on the area, possibly for the motive mentioned above, of moving outside of this area, or quite the opposite, by it's inhabitants not moving so much by vehicle, meaning a higher stay at home or activities nearby their residence. This drop continues even more on Sunday, which could be related to religious activities as well as possible local policies about certain activities.

#### Accidents by Month

```{r Temporal Analysis by Month}

## Accidents by Month
accidents <- accidents %>% filter(!is.na(Month))
ggplot(accidents, aes(x = Month, y = ..count.., group = 1)) +
  geom_line(stat = "count", color = "salmon", size = 1) +
  geom_point(stat = "count", color = "red", size = 3) +
  labs(title = "Distribution of Accidents by Month", x = "", y = "Number of Accidents") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The graph shows the monthly distribution of accidents in New York, highlighting clear trends throughout the year:

1. **Low Accident Rates (January-February)**: Accidents start at moderate levels in January and dip to their lowest in February, likely due to harsh winter weather reducing travel.

2. **Rising Accident Rates (March-June)**: Accidents increase sharply from March, peaking in June. This rise may be due to better weather, leading to more travel and increased road traffic.

3. **Plateau and Decline (July-November)**: After a slight drop in July, accident numbers steadily decline from August to November, possibly due to the transition to fall and reduced travel as the year progresses.

4. **Significant Drop (December)**: December sees a notable decrease in accidents, similar to January, possibly due to holiday periods and the onset of winter.

Accidents in New York peak in mid-year (April-June) and drop during winter months. Understanding these trends can help target road safety measures and reduce accidents during high-risk periods.

### Relevant factors 
There are several factors that can contribute to car accidents, such as weather conditions, vehicle types, and the reported reason that caused the accident.

Some of this factors range from traffic rules violations, illegal actions such as driving under the effects of alcohol or other impairing drugs and can be divided in different categories such as human error, mechanical error, environmental conditions, and medical conditions.

Note that the data comes from real accidents, reported by the victims themselves. This means that the data is complex and innacurate. After cleaning and filtering, a big part of the reports could not be categorized properly, so an extra category for all of these was made.

```{r Contributing Factors Analysis, cache=TRUE}
# 4. Contributing Factors Analysis
accidents %>%
  count(CONTRIBUTING.FACTOR.VEHICLE.1, sort = TRUE) %>%
  top_n(10) %>%
  ggplot(aes(area = n, fill = CONTRIBUTING.FACTOR.VEHICLE.1, 
             label = paste(CONTRIBUTING.FACTOR.VEHICLE.1, n, sep = "\n"))) +
  geom_treemap() +
  geom_treemap_text(colour = "white", place = "centre", size = 10) +
  labs(title = "Top 10 Contributing Factors (As reported)") +
  theme(legend.position = "none")
```

This plot shows how the top 10 contributing factors to accidents are distributed. The most common factors are "Driver Inattention/Distraction", "Failure to Yield Right-of-Way", and "Following Too Closely". These factors are often related to human error, which is a common cause of accidents.

"Unspecified" is the biggest category on this plot, which shows how many of the reports are lacking such important details, giving to tink about how seriously the involved parts along with law enforcement and insurance companies take this matter. 

It can be asumend that this "accidents" might have been of minor damage, probably with no injuries and hence the low importance.

```{r Contributing Factors Analysis categorized}
# 4. Contributing Factors Analysis
accidents %>%
  count(Category, sort = TRUE) %>%
  top_n(10) %>% 
  ggplot(aes(area = n, fill = Category, 
             label = paste(Category, n, sep = "\n"))) +
  geom_treemap() +
  geom_treemap_text(colour = "white", place = "centre", size = 10) +
  labs(title = "Top 10 Contributing Factors (Categorized)") +
  theme(legend.position = "none")
```

After categorizing the contributing factors, **Human error** is the most common cause of accidents, followed by **Unspecified**, then **Environmental Conditions** and **Mechanical Error**. At a first glance from the previous plot, it could be deduced that minor accidents of unknown nature are the most common, followed by "Distraction of the driver". After all human error causes are agregated, it becomes the biggest category.

This shows that most accidents are caused by human mistakes, such as inattention, distraction, or failure to yield right-of-way. 

#### Vehicle Type Analysis

```{r Vehicle Type Analysis, cache=TRUE}
# 6. Vehicle Type Analysis
# filter "" and " " values
accidents <- accidents %>% filter(VEHICLE.TYPE.CODE.1 != "" & trimws(VEHICLE.TYPE.CODE.1) != "")

accidents %>%
  count(VEHICLE.TYPE.CODE.1, sort = TRUE) %>%
  top_n(10) %>%
  mutate(VEHICLE.TYPE.CODE.1 = fct_reorder(VEHICLE.TYPE.CODE.1, n)) %>%
  ggplot(aes(x = n, y = VEHICLE.TYPE.CODE.1)) +
  geom_segment(aes(x = 0, xend = n, yend = VEHICLE.TYPE.CODE.1), color = "#3f3e3e",) +
  geom_point(size = 5, color = "orange") +
  labs(title = "Top 10 Vehicle Types Involved in Accidents", x = "Number of Accidents", y = "") +
  theme_minimal()+
  # adds number of accidents below the bars
  geom_text(aes(label = n), hjust = 0.5, size = 3, nudge_y = 0.4,)
```

The graph highlights the top 10 vehicle types involved in accidents in New York, offering insight into trends in vehicular safety. Sedans lead with over 31,000 incidents, likely due to their widespread use. SUVs and station wagons follow with more than 23,000 accidents, reflecting their popularity and the challenges of operating larger vehicles in urban settings.

Commercial vehicles such as taxis, pick-up trucks, and box trucks also account for a significant number of accidents. These vehicles are crucial to the city's transportation system, and their involvement in accidents points to the risks associated with heavy traffic use. Buses, integral to public transport, appear on the list as well, showing that even professional drivers face difficulties in dense traffic.

Smaller vehicles like bikes, e-bikes, and motorcycles are less frequently involved in accidents but still make the top 10, highlighting the vulnerabilities of these road users. Ambulances, while less involved, are also on the list, possibly due to the nature of their high-speed operations.

### Time Series Analysis

```{r Time Series Analysis, cache=TRUE}
# 7. Time Series Analysis
accidents %>%
  count(CRASH.DATETIME = floor_date(CRASH.DATETIME, "day")) %>%
  ggplot(aes(x = CRASH.DATETIME, y = n)) +
  geom_line(color = "blue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  labs(title = "Daily Accident Counts Over Time", x = "Date", y = "Number of Accidents") +
  theme_minimal() +
  ylim(0, 300)  # Set y-axis maximum to 500
```

The time series graph shows the daily count of accidents in New York over the course of 2021, with a visible trend line that highlights changes over time. Early in the year, there is a gradual increase in the number of accidents, which peaks around mid-year. This rise may reflect seasonal factors, such as increased travel and activity during warmer months.

As the year progresses into the latter half, the trend line begins to slope downward, indicating a decrease in accident frequency. This reduction could be associated with factors like reduced daylight hours in fall and winter, weather conditions, or changing traffic patterns as the year ends.

The day-to-day variability in accident counts, represented by the blue line, suggests that while there are general trends, daily fluctuations are significant, potentially driven by short-term factors like weather, events, or specific traffic incidents.

Overall, the graph provides insights into how accident rates evolved throughout the year, with clear periods of increase and decline, helping to identify patterns that could inform traffic safety measures and resource allocation.

### Borough Comparison

```{r Borough Comparison, cache=TRUE}
# 8. Borough Comparison
accidents %>%
  group_by(BOROUGH) %>%
  summarise(
    Injury_Rate = sum(IS.INJURED.ACCIDENT) / n(),
    Total_Accidents = n()
  ) %>%
  ggplot(aes(x = Total_Accidents, y = Injury_Rate, size = Total_Accidents, color = BOROUGH)) +
  geom_point(alpha = 0.7) +
  scale_size(range = c(3, 15)) +
  labs(title = "Injury Rate vs Total Accidents by Borough",
       x = "Total Number of Accidents", y = "Injury Rate") +
  theme_minimal()
```

The graph reveals several insights about the relationship between the number of accidents and injury rates across different boroughs in New York City. 

**The Bronx** stands out with a relatively large dot, indicating a high number of accidents. Its position on the graph suggests that the injury rate is on the higher side compared to other boroughs, which could point to more severe traffic conditions or less effective safety measures.

**Brooklyn** also has a significant number of accidents, as indicated by its large dot. However, its injury rate is slightly lower than that of the Bronx. This difference might suggest that Brooklyn has better safety measures in place or different traffic conditions that result in fewer injuries per accident.

**Manhattan**'s dot is smaller than those for the Bronx and Brooklyn, indicating fewer accidents overall. The injury rate for Manhattan is moderate, suggesting that while there are fewer accidents, the conditions or severity of these accidents might differ from those in other boroughs.

**Queens**, similar to Brooklyn, has a large dot, indicating a high number of accidents. The injury rate in Queens is comparable to Brooklyn, which might imply similar traffic conditions or safety measures in place.

**Staten Island**, on the other hand, has the smallest dot, indicating the fewest accidents among the boroughs. Its injury rate is also the lowest, suggesting that Staten Island might benefit from better traffic safety measures or less congested roads, leading to fewer and less severe accidents.

Overall, the graph provides a clear comparison of the injury rates and total number of accidents across different boroughs, highlighting areas where traffic safety could potentially be improved.

### Injuries and Deaths Analysis

#### Accidents with Injuries or Deaths by Weekday
```{r Accidents with Injuries or Deaths}

# Load necessary libraries
library(ggplot2)
library(dplyr)
library(fmsb)  # For radar chart

# Load your accident data
accident_data <- read.csv("data/merged_data_2021.csv")

# Filter for accidents with injuries
injured_accidents <- accident_data %>%
  filter(IS.INJURED.ACCIDENT == TRUE) %>%
  group_by(Weekday) %>%
  summarise(Accidents = n())

# Filter for accidents with deaths
deadly_accidents <- accident_data %>%
  filter(IS.DEADLY.ACCIDENT == TRUE) %>%
  group_by(Weekday) %>%
  summarise(Accidents = n())

# Filter for accidents with no injuries or deaths
no_injury_or_death_accidents <- accident_data %>%
  filter(IS.INJURED.ACCIDENT == FALSE & IS.DEADLY.ACCIDENT == FALSE) %>%
  group_by(Weekday) %>%
  summarise(Accidents = n())

# Ensure the weekday order is correct (Monday to Sunday)
injured_accidents$Weekday <- factor(injured_accidents$Weekday, 
                                    levels = c("Monday", "Tuesday", "Wednesday", 
                                               "Thursday", "Friday", "Saturday", "Sunday"))

deadly_accidents$Weekday <- factor(deadly_accidents$Weekday, 
                                   levels = c("Monday", "Tuesday", "Wednesday", 
                                              "Thursday", "Friday", "Saturday", "Sunday"))

no_injury_or_death_accidents$Weekday <- factor(no_injury_or_death_accidents$Weekday, 
                                               levels = c("Monday", "Tuesday", "Wednesday", 
                                                          "Thursday", "Friday", "Saturday", "Sunday"))

# Apply log transformation
injured_accidents$LogAccidents <- log1p(injured_accidents$Accidents)
deadly_accidents$LogAccidents <- log1p(deadly_accidents$Accidents)
no_injury_or_death_accidents$LogAccidents <- log1p(no_injury_or_death_accidents$Accidents)

# Reorder the data frame based on the correct weekday order
injured_accidents <- injured_accidents %>%
  arrange(Weekday)

deadly_accidents <- deadly_accidents %>%
  arrange(Weekday)

no_injury_or_death_accidents <- no_injury_or_death_accidents %>%
  arrange(Weekday)

# Prepare data for the radar chart (Injured)
radar_data_injured <- as.data.frame(t(injured_accidents$LogAccidents))
colnames(radar_data_injured) <- injured_accidents$Weekday
radar_data_injured <- rbind(rep(max(injured_accidents$LogAccidents), 7), # Maximum value for scaling
                            rep(min(injured_accidents$LogAccidents), 7), # Minimum value for scaling
                            radar_data_injured)

# Prepare data for the radar chart (Deadly)
radar_data_deadly <- as.data.frame(t(deadly_accidents$LogAccidents))
colnames(radar_data_deadly) <- deadly_accidents$Weekday
radar_data_deadly <- rbind(rep(max(deadly_accidents$LogAccidents), 7), # Maximum value for scaling
                           rep(min(deadly_accidents$LogAccidents), 7), # Minimum value for scaling
                           radar_data_deadly)

# Prepare data for the radar chart (No Injuries or Deaths)
radar_data_no_injury_or_death <- as.data.frame(t(no_injury_or_death_accidents$LogAccidents))
colnames(radar_data_no_injury_or_death) <- no_injury_or_death_accidents$Weekday
radar_data_no_injury_or_death <- rbind(rep(max(no_injury_or_death_accidents$LogAccidents), 7), # Maximum value for scaling
                                       rep(min(no_injury_or_death_accidents$LogAccidents), 7), # Minimum value for scaling
                                       radar_data_no_injury_or_death)

# Set up the plotting area to display three plots side by side
par(mfrow = c(1, 3))  # Set up a 1x3 plotting area
par(oma = c(0, 0, 4, 0))  # Set outer margins to make space for the main title

# Plot the radar chart for Injured Accidents
radarchart(radar_data_injured, axistype = 1,
           pcol = "blue", pfcol = scales::alpha("blue", 0.5), plwd = 2,
           cglcol = "grey", cglty = 1, axislabcol = "transparent",
           caxislabels = NA,  # Remove gray numbers
           cglwd = 0.8,
           vlcex = 0.8)
title(main = "with Injuries")

# Plot the radar chart for Deadly Accidents
radarchart(radar_data_deadly, axistype = 1,
           pcol = "red", pfcol = scales::alpha("red", 0.5), plwd = 2,
           cglcol = "grey", cglty = 1, axislabcol = "transparent",
           caxislabels = NA,  # Remove gray numbers
           cglwd = 0.8,
           vlcex = 0.8)
title(main = "with Deaths")

# Plot the radar chart for No Injuries or Deaths
radarchart(radar_data_no_injury_or_death, axistype = 1,
           pcol = "green", pfcol = scales::alpha("green", 0.5), plwd = 2,
           cglcol = "grey", cglty = 1, axislabcol = "transparent",
           caxislabels = NA,  # Remove gray numbers
           cglwd = 0.8,
           vlcex = 0.8)
title(main = "without Injuries or Deaths")

# Add a big title to the entire plot
mtext("Accidents per Weekday", outer = TRUE, cex = 2, font = 2)

```

The shown plots above shall be used as another step into a deeper analysis of when accidents are happening in New York.
The plot shows three radar charts that compare the occurrence of accidents by weekday across three different categories: accidents with injuries, accidents with deaths, and accidents without injuries or deaths.

In the first chart, shaded in blue, accidents with injuries are displayed. The chart indicates that such accidents are fairly evenly distributed throughout the week, with a slight increase towards the end of the week, particularly on Friday and Saturday. There is a noticeable decrease on Monday, suggesting that fewer injury-related accidents occur at the start of the week.

The middle chart, shaded in red, focuses on accidents that result in deaths. This chart shows a clear concentration of deadly accidents towards the end of the week, especially on Friday and Saturday. In contrast, the beginning of the week, particularly Monday and Tuesday, sees fewer accidents with fatalities.

The third chart, shaded in green, represents accidents that do not result in injuries or deaths. These accidents appear to be more evenly spread throughout the week, with a slight increase during the middle of the week, particularly on Wednesday. The frequency of these accidents is lower on Sunday and Monday.

Overall, the charts reveal that accidents involving injuries and deaths tend to increase towards the weekend, while accidents without injuries or deaths occur more consistently throughout the week, with minor variations. The visual representation highlights the differences in accident patterns across the days of the week, with distinct trends for each type of accident.

With this information, the team decided to dig one layer deeper to find out, on what time, what type of accidents happen mostly and gain some insightful information with that.

#### Heatmap Analysis of Accidents and Injuries

```{r Heatmap Accidents with Injuries}
library(ggplot2)
library(dplyr)

# Load your accident data
accidents_df <- read.csv("data/merged_data_2021.csv", header=TRUE)

# Filter for the relevant days and reorder factors
base_filtered_df <- accidents_df %>%
        filter(Weekday %in% c("Thursday", "Friday", "Saturday")) %>%
        mutate(TimeOfDay = factor(TimeOfDay, levels = c("Early Morning", "Morning", "Afternoon", "Late Afternoon", "Evening", "Night")),
               Weekday = factor(Weekday, levels = c("Saturday", "Friday", "Thursday")))

# Filter data for accidents with injuries
injured_filtered_df <- base_filtered_df %>%
        filter(IS.INJURED.ACCIDENT == TRUE)

# Aggregate data for accidents with injuries
agg_injured_df <- injured_filtered_df %>%
        group_by(Weekday, TimeOfDay) %>%
        summarise(Accidents = n()) %>%
        ungroup()

# Create the heatmap for accidents with injuries
p1 <- ggplot(agg_injured_df, aes(x = TimeOfDay, y = Weekday, fill = Accidents)) +
        geom_tile(color = "white") +
        scale_fill_gradient(low = "white", high = "red") +
        labs(title = "Accidents with Injuries", x = "Time of Day", y = "Weekday (reversed order)", fill = "Number of Accidents") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Display the plot
print(p1)

```




```{r Heatmap Accidents with Deaths}
library(ggplot2)
library(dplyr)

# Filter data for accidents with deaths
deadly_filtered_df <- base_filtered_df %>%
        filter(IS.DEADLY.ACCIDENT == TRUE)

# Aggregate data for accidents with deaths
agg_deadly_df <- deadly_filtered_df %>%
        group_by(Weekday, TimeOfDay) %>%
        summarise(Accidents = n()) %>%
        ungroup()

# Create the heatmap for accidents with deaths
p2 <- ggplot(agg_deadly_df, aes(x = TimeOfDay, y = Weekday, fill = Accidents)) +
        geom_tile(color = "white") +
        scale_fill_gradient(low = "white", high = "red") +
        labs(title = "Accidents with Deaths", x = "Time of Day", y = "Weekday (reversed order)", fill = "Number of Accidents") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Display the plot
print(p2)

```


```{r Heatmap Accidents without Injuries or Deaths}
library(ggplot2)
library(dplyr)

# Filter data for accidents with no injuries or deaths
no_injury_or_death_filtered_df <- base_filtered_df %>%
        filter(IS.INJURED.ACCIDENT == FALSE & IS.DEADLY.ACCIDENT == FALSE)

# Aggregate data for accidents without injuries or deaths
agg_no_injury_or_death_df <- no_injury_or_death_filtered_df %>%
        group_by(Weekday, TimeOfDay) %>%
        summarise(Accidents = n()) %>%
        ungroup()

# Create the heatmap for accidents without injuries or deaths
p3 <- ggplot(agg_no_injury_or_death_df, aes(x = TimeOfDay, y = Weekday, fill = Accidents)) +
        geom_tile(color = "white") +
        scale_fill_gradient(low = "white", high = "red") +
        labs(title = "Accidents without Injuries or Deaths", x = "Time of Day", y = "Weekday (reversed order)", fill = "Number of Accidents") +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Display the plot
print(p3)

```

As mentioned in previous plot, with the knowledge acquired, the team decided to focus now on the Time of day, where accidents occurred in 2021.

In the first heatmap, titled "Accidents with Injuries," the data is shown for Thursday, Friday, and Saturday across different times of the day. The color intensity indicates the number of accidents, with darker reds representing higher numbers. The highest concentration of accidents with injuries occurs on Friday afternoons, as indicated by the darkest red square. This suggests that the risk of accidents causing injuries peaks during this time.

The second heatmap, titled "Accidents with Deaths," similarly shows data for Thursday, Friday, and Saturday. The most intense red, representing the highest number of fatal accidents, is observed on Thursday mornings and Saturday early mornings. This indicates that fatal accidents are more likely to occur during these times. The distribution is more varied across the different times of day and days of the week compared to accidents with injuries.

The third heatmap, titled "Accidents without Injuries or Deaths," also covers the same days of the week and times of day. Here, the darkest red, indicating the highest number of non-injury, non-fatal accidents, is again centered on Friday afternoons. This suggests that, similar to accidents with injuries, non-injury accidents also peak in the afternoon on Fridays.

In summary, all three heatmaps reveal patterns in the timing and frequency of different types of accidents. Accidents, whether resulting in injuries, deaths, or neither, tend to cluster around specific times of the day, particularly Friday afternoons. However, fatal accidents are more likely to occur early in the day on Thursdays and Saturdays.

## Chapter of Choice (Esquisse)
### If you like Tableau, you will love Esquisse

Esquisse is a package that allows you to create interactive plots and dashboards in R. 
It is similar to Tableau in that it provides a user-friendly interface for creating visualizations without writing code. After loading your data, you can create plots interactively by dragging and dropping variables.

To use Esquisse, you need to install the package and then load it in your R script. 
After loading the package, you can launch the web app by calling the `esquisser()` function with your data as an argument.
That opens a web browser with the Esquisse interface, where you can create plots interactively by dragging and dropping variables.
Esquisse works with the `plotly` package to create interactive plots.

```{r Esquisse, eval=FALSE }
library(esquisse)
library(plotly)
options(shiny.maxRequestSize=300*1024^2) # Increase the maximum request size for Shiny apps
esquisser(data) # Opens the web app in the Viewer pane or in the browser with the data loaded
```

![Esquisse](resources\esquisse.png)

<div class="alert alert-primary" role="alert">

NOTE:
Trying to load the data was tricky, Esquisse would not load the data from the merged dataset on the code.
Opening Esquisse without an argument would start the app and prompt to load the data from the interface, but it would not load the data from the code.

Now trying to load the data from the interface, a warning message on the UI finally tells the problem, that loading more than 5MB of data was not possible.

This is a limitation of the Shiny app, which is used to create the Esquisse interface. The maximum request size for Shiny apps is 5MB by default, which is not enough for our dataset. It could have been a deal breaker for the use of Esquisse in this project and any other with a large dataset.

To solve this issue, it's necessary to increase the maximum request size for Shiny apps by setting the `options(shiny.maxRequestSize)` option to a higher value. In this case is set it to 300MB, which should be enough for the merged dataset.

</div>


At the bottom left of the pane, in the options tab, you can select to make the plots with `plotly` to make them interactive.
Once active, you can hover over the plots to see the data points and values or click on the legend to filter the data.

![Esquisse Options](resources\esquisse_plotly.png)

#### Injuries by Hour

![Esquisse Plot](resources\esquisse people injured.png)

In this plot, the number of accidents with injuries is shown by the hour of the day. The plot reveals that after 10 AM, the number of accidents with injuries increases repidly, peaking by midnight. 

This can be attributed to various factors, such as increased traffic during the day, driver fatigue, and reduced visibility at night. Also as shown in the categories before, it could be related to alcohol consumption or other drugs, which are more likely to be consumed during the night.

#### Deaths by Hour

![Esquisse Plot](resources\esquisse people killed.png)

This plot shows the number of accidents with deaths by the hour of the day. The plot indicates that the number of fatal accidents is relatively low during the day, with a slight increase in the evening. However, the number of fatal accidents rises significantly after midnight, peaking in the early morning hours.

This trend suggests that fatal accidents are more likely to occur during the night and early morning, again, possibly due to factors such as reduced visibility, driver fatigue, increased risk-taking behavior, and impaired driving due to alcohol or drugs.

This two plots are important to understand the risks of accidents at different times of the day and when accidents are more likely to result in injuries or fatalities. This information can help inform traffic safety measures and interventions to reduce the number of accidents and improve road safety.

### About Esquisse

Esquisse is a powerful tool for creating interactive plots and dashboards in R. It provides a user-friendly interface that allows you to create visualizations without writing code. The drag-and-drop functionality makes it easy to explore your data and create custom plots quickly.

For users familiar with Tableau or other data visualization tools, Esquisse offers a similar experience in R. You can create a wide range of plots, including scatter plots, bar charts, line graphs, and more. The interactive features allow you to explore your data in depth and gain insights into patterns and trends.

Esquisse is a valuable tool for data analysis, exploratory data visualization, and sharing insights with others. It is especially useful for users who prefer a visual interface for creating plots and dashboards. With Esquisse, you can create professional-looking visualizations that enhance your data analysis and storytelling.

Nevertheless, it comes with some limitations when compared with other software. 
It might not be as intuitive or powerful as Tableau, and it may not offer the same level of customization or advanced features.
Also, the size of the dataset is limited by the maximum request size for Shiny apps, which can be a constraint for large datasets and has to be changed manually.

Overall, Esquisse is a valuable tool for creating interactive plots and dashboards in R, and it can be a great addition to your data analysis toolkit.

## Shiny Application

```{r Shiny, eval= FALSE }
# Load necessary libraries
library(shiny)
library(ggplot2)
library(dplyr)
library(lubridate)

# Load the data
accident_data <- read.csv("data/merged_data_2021.csv", header = TRUE)
accident_data$CRASH.DATE <- as.Date(accident_data$CRASH.DATE)
min_date <- min(accident_data$CRASH.DATE, na.rm = TRUE)
max_date <- max(accident_data$CRASH.DATE, na.rm = TRUE)

# Define UI for the Shiny app
ui <- fluidPage(
        titlePanel("Accident Data Filter"),
        sidebarLayout(
                sidebarPanel(
                        dateRangeInput("date_range", "Select Date Range:",
                                       start = min_date,
                                       end = max_date,
                                       min = min_date,
                                       max = max_date),
                        selectInput("weekday", "Select Weekday(s):",
                                    choices = unique(accident_data$Weekday),
                                    selected = c("Monday", "Wednesday", "Friday"),
                                    multiple = TRUE),
                        checkboxInput("is_deadly", "Accidents with Death(s)", value = FALSE),
                        checkboxInput("is_injured", "Accidents with injured people", value = FALSE),
                        actionButton("filter", "Apply Filters")
                ),

                mainPanel(
                        plotOutput("accident_plot")
                )
        )
)
# Define server logic for the Shiny app
server <- function(input, output) {

  filtered_data <- reactive({
    data <- accident_data

    # Extract start and end dates from the input
    start_date <- input$date_range[1]
    end_date <- input$date_range[2]

    # Filter by the date range
    data <- data %>% filter(CRASH.DATE >= start_date & CRASH.DATE <= end_date)

    # Filter by weekdays
    data <- data %>% filter(Weekday %in% input$weekday)

    # Filter by deadly accidents
    if (input$is_deadly) {
      data <- data %>% filter(IS.DEADLY.ACCIDENT == TRUE)
    }

    # Filter by injured accidents
    if (input$is_injured) {
      data <- data %>% filter(IS.INJURED.ACCIDENT == TRUE)
    }

    return(data)
  })

  output$accident_plot <- renderPlot({
    data <- filtered_data()

    # Summarize the data to get the count of accidents per weekday
    data_summary <- data %>%
            group_by(Weekday) %>%
            summarise(Number_of_Accidents = n())

    # Plot the number of accidents by weekday
    ggplot(data_summary, aes(x = Weekday, y = Number_of_Accidents, fill = Weekday)) +
            geom_bar(stat = "identity") +
            labs(title = "Number of Accidents by Weekday",
                 x = "Weekday",
                 y = "Number of Accidents") +
            theme_minimal()
  })
}

# Run the application
shinyApp(ui = ui, server = server)
```
Below is a simple **Shiny** app, where users are able to select a date range (default takes the first and last date of the loaded dataset), the weekday(s) specify whether only accidents with Death(s) and/or injured people should be included it in.
Depending on the selection, the plots is automatically being updated giving the user a direct feedback for doing some very basic analysis of how many accidents happen on what specific weekdays given the date range.

![Shiny Application](resources\shiny.png)

> It is important to clarify that the above mentioned Esquisse is a Shiny application, that essentially is tailored to setup on the UI the plots that the user wants to see by clicking and dragging the variables, while the setup for the Shiny app is done by the developer, where the user can only select the variables to be shown. More functionality can be added to the Shiny app, but it requires more coding.

## Interactive Map of Accidents in New York

This section showcases an interactive map of accidents in New York using the `plotly` package.
The map shows the density of accidents based on latitude and longitude coordinates, with color indicating the density of accidents in each area.
It is an interactive map that allows you to zoom in and out and hover over data points to see more information.

In the first view, it can look like that the whole New York is yellow, but when zooming in, the graph reveals the density of accidents in each area. This is to be expected and is due to the high number of inhabitants and accidents in New York.

It is interesting to see that the accidents are concentrated in certain areas, such as Manhattan and Brooklyn, which are more densely populated and have more traffic. Also, can be appreciated a trend that horizontal roads (East-West) have more accidents than vertical roads (North-South).

Also, as expected, the accidents are more concentrated in main roads and highways, where the traffic is heavier, until a bridge is reached. In the map, virtually all bridges are free of accidents, which is a good sign for traffic safety.

```{r}
accidents <- read.csv("data/merged_data_2021.csv")
library(plotly)

# filter latitude and longitude equal to 0
accidents <- accidents[accidents$LATITUDE != 0 & accidents$LONGITUDE != 0,]

fig <- accidents 
fig <- fig %>%
  plot_ly(
    type = 'densitymapbox',
    lat = ~LATITUDE,
    lon = ~LONGITUDE,
    coloraxis = 'coloraxis',
    alpha = 0.6,
    alpha_stroke = 0.3,
    radius = 4) 
fig <- fig %>%
  layout(
    mapbox = list(
      style="open-street-map",
      center= list(lat=40.7128, lon=-74.0060),  # Coordinates for New York
      zoom = 8.5),  # Adjust zoom level as needed
    coloraxis = list(colorscale = 'Viridis'))

fig
```


## ChatGPT with its highs and lows

When we first set out on our data science project, we were excited but also a bit overwhelmed. We knew we were dealing with a complex problem—massive datasets, intricate relationships, and the need to create meaningful visualizations that could reveal the insights hidden within the data. As much as we loved diving into R and exploring the depths of data manipulation, we also knew that the journey ahead would be challenging and time-consuming. That’s when we decided to bring ChatGPT into our process.

Initially, we approached ChatGPT with cautious optimism. Could an AI really help us navigate the complexities of data science? Could it generate R code that would actually work? Well, we obviously knew the answer; Yes! Whether we were stuck on which plot would best represent our data or needed help writing a tricky piece of R code, ChatGPT was there, offering suggestions that we hadn’t even thought of. It became our go-to resource, a kind of brainstorming partner that was always available and always ready with ideas.

For example, when we were trying to figure out how to visualize our data, ChatGPT suggested options like heatmaps, radar charts, and density plots. Not only did it give us the idea, but it also provided the R code to create these visualizations. This saved us countless hours that we would have otherwise spent tweaking and troubleshooting code. When we encountered errors—inevitable in any data science project—ChatGPT was incredibly helpful in diagnosing the issues and suggesting fixes. It was like having a personal R consultant available at all times.

However, as much as ChatGPT boosted our productivity, it also taught us an important lesson: even with AI, the human touch is irreplaceable. We quickly learned that while ChatGPT could provide code and suggest visualizations, these outputs needed to be rigorously checked. Sometimes, the code didn’t produce exactly what we wanted, or the visualization didn’t tell the story we were trying to convey. We had to step back, critically evaluate the results, and make adjustments to ensure that our analysis was accurate and meaningful.

Another interesting challenge we faced was the impact of having so much information and functionality at our fingertips. Using ChatGPT made our process incredibly efficient, but it also shortened the time we usually spent brainstorming and exploring different approaches. There’s something to be said for the creative process that comes from struggling with a problem and experimenting with various solutions. With ChatGPT, we sometimes found that this creative journey was cut short, as solutions were so readily available. It was a trade-off between efficiency and the creative exploration that often leads to unexpected insights in data science.

Yet, in today’s data-driven world, where the ability to quickly analyze and interpret data is crucial, using AI tools like ChatGPT has become almost essential. The efficiency gains we experienced were undeniable. We could spend less time wrestling with the syntax of R and more time focusing on the bigger picture—interpreting the data, refining our analyses, and communicating our findings. ChatGPT didn’t take away our ability to think critically or creatively; instead, it enhanced our ability to execute on those thoughts more quickly and with greater precision.

Reflecting on our experience, it’s clear that using ChatGPT was like having a turbocharged assistant in our data science toolkit. It didn’t replace our skills in R or our understanding of data, but it did significantly streamline our workflow. We were able to focus more on the insights and less on the mechanics, which made our project not only faster but also richer in the insights we could uncover.

In conclusion, while tools like ChatGPT are reshaping the way we approach data science, they also remind us of the importance of maintaining our critical thinking and creativity. AI can accelerate the process, but it’s still up to us to ensure that the results are accurate, meaningful, and aligned with our goals. In the end, the combination of human insight and AI-driven efficiency is what made our project a success, and it’s a balance we’ll continue to seek in future endeavors.

## Conclusion

In this project, we explored a dataset of traffic accidents in New York City from 2016 to 2022, focusing on the data from 2021. We analyzed various aspects of the accidents, including the time, location, contributing factors, vehicle types, and injuries or deaths. Through data visualization and analysis, we gained insights into the patterns and trends of accidents in New York, helping to identify areas for traffic safety improvement.

We found that human error is the most common cause of accidents, with factors like inattention, distraction, and failure to yield right-of-way contributing to a significant number of incidents. Sedans and SUVs are the most common vehicle types involved in accidents, reflecting their widespread use in the city. Accidents are more likely to occur during the day, with a peak in the afternoon and evening hours.

By analyzing the data by borough, we identified differences in accident rates and injury rates across different areas of New York City. The Bronx and Brooklyn have higher accident rates and injury rates, while Staten Island has the lowest rates. These insights can inform targeted traffic safety measures and interventions to reduce accidents and improve road safety.

